"id"	"byq2110261409"
"file_path"	"data_raw\glo\env\ocean_zones\copernicusmarineservicecmems\byq2110261409"
"local_path"	"D:\Storage\Repositories\wiosym"
"download_date"	"2021-10-26"
"user"	"byq"
"provider_list"	"none"
"provider_manual"	"Copernicus Marine Service (CMEMS)"
"source"	"https://my.cmems-du.eu/motu-web/Motu --service-id GLOBAL_REANALYSIS_BIO_001_029-TDS --product-id global-reanalysis-bio-001-029-monthly --longitude-min 5.5 --longitude-max 80.5 --latitude-min -42.5 --latitude-max 18.56 --depth-min 0 --depth-max 50 --date-min \"2015-01-01 00:00:00\" --date-max \"2019-12-01 00:00:00\" --variable no3"
"citation"	"Copernicus Marine Service (CMEMS)"
"copyright"	"Open - product and raw data can be downloaded"
"copyright_details"	"Copernicus Marine Service
Provides free, open, regular and systematic reference information on the blue (physical), white (sea ice), and green (biogeochemical) ocean state, variability and dynamics across the global ocean and European regional seas."
"location"	"glo"
"theme"	"Environmental (e.g. bathymetry)"
"theme_tag"	"env"
"subtheme"	"Ocean zones (e.g. photic, open ocean, climate zone)"
"subtheme_tag"	"ocean_zones"
"tags"	";env;ocean zones;oceanography;ocean chemistry;ocean zones;pollution;organic pollution;nutrient pollution;pelagic habitat;"
"comments"	" ! python -m motuclient \
            --motu https://my.cmems-du.eu/motu-web/Motu \
            --service-id GLOBAL_REANALYSIS_BIO_001_029-TDS \
            --product-id global-reanalysis-bio-001-029-monthly \
            --longitude-min 5.5 --longitude-max 80.5 --latitude-min -42.5 --latitude-max 18.56 \
            --depth-min 0 --depth-max 50 \
            --date-min '2015-01-01 00:00:00' --date-max '2019-12-01 00:00:00' \
            --variable no3 \
            --out-name CMEMS_dataset.nc


if 'depth' in data.dims:
    data = data.mean(dim='depth')
# Average months together first, then by season, then by year to limit impact of reduced data at certain times of year-
month_length = data.time.dt.days_in_month

# Calculate the weights by grouping by 'time.month'.
weights = month_length.groupby('time.month') / month_length.groupby('time.month').sum()

# Test that the sum of the weights for each season is 1.0
np.testing.assert_allclose(weights.groupby('time.month').sum().values, np.ones(12))

# Calculate the weighted average
clim = (data * weights).groupby('time.month').sum(dim='time')

# Now do climatological average
out = clim.mean(dim='month')

if 'lon' in data.dims:
    lons, lats = np.meshgrid(out.lon.values,out.lat.values) 
    valid = np.isfinite(out[variable].values.flatten())
if 'longitude' in data.dims:
    lons, lats = np.meshgrid(out.longitude.values,out.latitude.values) 
    valid = np.isfinite(out[variable].values.flatten())"
