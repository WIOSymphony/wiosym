# =========================================================================================================
# Script by Edmond Sacre, SLU
# This script creates distribution models based on occurrence records
# This script also resamples the rasters to the same resolution and extent as the standard WIOSym grid
# =========================================================================================================

# PREPARATIONS
```{r, include = FALSE}
# Install / load packages
#x <- c("sf", "raster", "tidyr", "dplyr")
#install.packages(x, dependencies=TRUE)
```

## Install packages
```{r, include = FALSE}
library(sf)
library(raster)
library(fasterize)
library(tidyr)
library(dplyr)
library(rgdal)
library(tidyverse)
library(leaflet)
```

## View folders/themes
```{r}
#folders_raw <- read.table("./shiny_data_upload/folders.txt", sep = "\t", header = TRUE)
#folders_data <- read.table("./process/templates/folders_data.txt", sep = "\t", header = TRUE)
#folders <- folders_raw %>% add_row(folders_data)
```

## Define versions/directories
```{r}
version = "v02"
d_version = ".0"
location = "reg"   #check
theme1 <- "eco"   #check
subtheme1 <- "bfish_coral"   #check
name1 <- "coralfish_sdm"   #check
name2 <- "" #check
(dest1_path <- paste("./data", location, theme1, subtheme1, name1, version, sep="/"))
(work1_path <- paste(dest1_path, "proc", sep="/"))
(proc1_path <- paste(dest1_path, "proc_log", sep="/"))
script_path <- "./process/r"
(script_path_windows <- paste(getwd(), "/process/r", sep=""))
(script_name <- paste(theme1, "_", subtheme1,"_", location, "_", name1,"_s01_",version, ".R", sep=""))
```

## Create directories
```{r}
dir.create(dest1_path, recursive = TRUE)
dir.create(work1_path, recursive = TRUE)
dir.create(proc1_path, recursive = TRUE)
```

## Read in WIOSym standard grid
```{r}
grid_1km <- raster("./data/reg/grid/grid/v01/grid_1km_v01.1.tif")
grid_1km_proj <- raster("./data/reg/util/grid_1km_proj.tif")
```

## Define sources
```{r}
num_sources <- 2  # write the number of sources you will use in this script (to be used later for exporting metadata)
  
source1_dir <-  "./data_raw/glo/eco/spec/obis/es2202041521/"    #check
source1_id <- "es2202041521"    #check
source1_metasym <- read.table(paste0(source1_dir, source1_id, "_metasym.txt"), sep = "\t")
#source1_metasym # check that metasym file is populated, and fix if not - before finalising the processing

source2_dir <-  "./data_raw/reg/env/ocean/copernicus/es2204071326/"   #check
source2_id <- "es2204071326"    #check
source2_metasym <- read.table(paste0(source1_dir, source1_id, "_metasym.txt"), sep = "\t")
#source2_metasym # check that metasym file is populated, and fix if not - before finalising the processing

source_list <- c(source1_id, source2_id) # for multiple sources, should look like - c(source1_id, source2_id, source3_id) etc.
```

*****************************************************************
*****************************************************************
# PROCESSING

# Install processing specific packages
```{r, include = FALSE}
library(robis)
library(spatstat)
library(spatialEco)
library(raster)
library(sf)
library(sp)
library(sdm)
library(mapview)
library(RColorBrewer)
library(scales)
```

# Specify specific taxa to model, e.g. genus
```{r}
tax_name <- 'Siganus'
```

# Specify taxon for which to pull sightings data from OBIS
# Taxon IDs can be found at https://www.marinespecies.org/index.php

# Labridae = 125541
# Muraenidae = 125431
# Chaetodontidae = 125528
# Scaridae = 125557
# Siganidae = 125562
```{r}
# IF ONLY ONE TAXON GROUP IS DESIRED
spec <- occurrence(taxonid = 125562, geometry = "POLYGON ((86.66016 23.88584, 89.12109 -47.27923, 
                   -22.14844 -48.34165, -22.50000 21.77991, 86.66016 23.88584))",
                   startdate = as.Date("2000-01-01"))

#map_leaflet(spec, popup = function(x){x["scientificName"]})
```

```{r}
# Identify taxa with most observations
temp <- dplyr::count(spec, genus)
temp <- filter(temp, n > 0)
```

```{r}
# Select specific species/genus
spec_temp <- filter(spec, grepl(tax_name, scientificName))
map_leaflet(spec_temp, popup = function(x){x["scientificName"]})
spec <- spec_temp
```

# Convert OBIS sightings to spatial points object
```{r}
xy <- spec[, c("decimalLongitude", "decimalLatitude")]
spec_sp <- SpatialPointsDataFrame(coords = xy, data = spec, proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
species <- spec_sp
```

```{r}
temp <- as.data.frame(species)
```

# Import predictor layers
```{r}
lst <- list.files("./data/reg/util/sdm_predictors/", full.names = T)
preds <- stack(lst)
species$Occurrence <- 1
species <- species[,"Occurrence"]
e <- raster::extract(preds, species, method = "simple") # Extract predictor values to points
species <- cbind(species, e)
temp <- as.data.frame(species)
temp <- temp[rowSums(is.na(temp)) <= 10,] # Remove points with NA in more than 10 predictors
xy <- temp[, c("decimalLongitude", "decimalLatitude")]
spec <- subset(temp, select=-c(decimalLongitude,decimalLatitude))
species <- SpatialPointsDataFrame(coords = xy, data = spec, proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
plot(preds, maxnl = 32)
```

# Determine number of pseudo absences
```{r}
temp <- as.data.frame(species)
pn <- nrow(temp[!duplicated(temp),])
bgn <- pn
if(bgn < 100){bgn <- 100}
#bgn <- 3000 # manual number
```

# If desired, decrease the resolution of the predictions to speed up processing time (e.g. for testing)
```{r}
preds <- aggregate(preds, fact = 3)
```

# Run ensemble distribution modelling
```{r, warning=FALSE}
d <- sdm::sdmData(formula = Occurrence~., train = species, predictors = preds, bg=list(n = bgn, remove = TRUE))
d
m1 <- sdm(Occurrence~.,data=d,methods=c('brt','svm','glm','rf'), n = 1, replication = "sub")
m1
write.sdm(d, filename = paste0(work1_path,"/", name1, "_sdmdata"), overwrite = T)
write.sdm(m1, filename = paste0(work1_path,"/", name1, "_sdmmodel"), overwrite = T)
```

```{r}
# Ensemble model
e1 <- ensemble(m1,newdata=preds,filename='e1.tif',setting=list(method='weighted',stat='TSS'), overwrite=T, nc=6)
mapview(-e1, col.regions = brewer.pal(11, "Spectral"))
```

```{r}
# Other analytics of interest
#rcurve(m1, id =4)
#getVarImp(m1, id = 1)
```

```{r}
# Evaluation
getEvaluation(m1, w = 1:4, opt = 1, stat = 'threshold')
evaluates(d, e1)
cut <- evaluates(d, e1)@threshold_based$threshold[1]
#cut <- min(getEvaluation(m1, w = 1:4, opt = 1, stat = 'threshold')$threshold) # Take the minimum threshold (to be conservative)
```

# Model with threshold presence/absence cutoff
```{r}
prod <- e1
prod[prod < cut] <- NA # apply thresholds?
product1 <- projectRaster(prod, crs = crs(grid_1km))
product1 <- resample(product1, grid_1km)
product1[product1 == 0] <- NA
product1[] <- scales::rescale(product1[], to = c(1, 100))
product1[is.na(product1)] <- 0
product1[is.na(grid_1km)==TRUE] <- NA
prod_cut <- product1
(dest_temp <- paste0(dest1_path, "/", subtheme1, "_", name1, 
                     ifelse(tax_name == "", tax_name, paste0("_", sub(" ", "_", tax_name))),
                     "_cutoff_pn", pn, "_bgn", bgn, "_", version, d_version, ".tif"))
writeRaster(prod_cut, dest_temp, COMPRESS=LZW, overwrite=TRUE)

mapview(-prod_cut, col.regions = brewer.pal(11, "Spectral"))
```

# Model without threshold presence/absence cutoff
```{r}
prod <- e1
#prod[prod < cut] <- NA # apply thresholds?
product1 <- projectRaster(prod, crs = crs(grid_1km))
product1 <- resample(product1, grid_1km)
product1[product1 == 0] <- NA
product1[] <- scales::rescale(product1[], to = c(1, 100))
product1[is.na(product1)] <- 0
product1[is.na(grid_1km)==TRUE] <- NA
prod_nocut <- product1
(dest_temp <- paste0(dest1_path, "/", subtheme1, "_", name1, 
                     ifelse(tax_name == "", tax_name, paste0("_", sub(" ", "_", tax_name))),
                     "_nocutoff_pn", pn, "_bgn", bgn, "_", version, d_version, ".tif"))
#writeRaster(prod_nocut, dest_temp, COMPRESS=LZW, overwrite=TRUE)

mapview(-prod_nocut, col.regions = brewer.pal(11, "Spectral"))
```

# STOP RUN HERE FOR INDIVIDUAL TAXA SUB MODELS

# Combine sdms for different species to get a measure of species richness
```{r}
eco1 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Chaetodon_cutoff_pn318_bgn318_v02.0.tif")
eco2 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Chlorurus_cutoff_pn22_bgn100_v02.0.tif")
eco3 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Echidna_cutoff_pn19_bgn100_v02.0.tif")
eco4 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Gymnothorax_cutoff_pn177_bgn177_v02.0.tif")
eco5 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Halichoeres_cutoff_pn119_bgn119_v02.0.tif")
eco6 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Heniochus_cutoff_pn47_bgn100_v02.0.tif")
eco7 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Scarus_cutoff_pn72_bgn100_v02.0.tif")
eco8 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Siganus_cutoff_pn44_bgn100_v02.0.tif")
eco9 <- raster("./data/reg/eco/bfish_coral/coralfish_sdm/v02/bfish_coral_coralfish_sdm_Thalassoma_cutoff_pn106_bgn106_v02.0.tif")

eco <- eco1+eco2+eco3+eco4+eco5+eco6+eco7+eco8+eco9
product1 <- eco

mapview(-eco, col.regions = brewer.pal(11, "Spectral"))
```

# Mask by coral reef layer
```{r}
coral <- raster("data/reg/eco/bh_coral/v02/coral_reef_proportion_saya_1km_v02.2.tif")
coral[coral > 0] <- 1
product1 <- product1*coral
mapview(-product1, col.regions = brewer.pal(11, "Spectral"))
mapview(-coral, col.regions = brewer.pal(11, "Spectral"))
```

# Set values in Chagos archipelago to between 1200 and 1600 kg/ha of fish biomass and scale all other reefs from 1 to 1200
# Based on information from Graham et al 2013 https://link.springer.com/chapter/10.1007/978-94-007-5965-7_19
# Figure 19.9
# Some reefs have even higher biomass in Chagos, but we use an upper limit of 1800 so Chagos does not dwarf other reefs in the WIO
```{r}
grid_1km <- grid_1km * 0

e <- extent(6300000, 6700000, -920000, -500000)
chag <- crop(product1, e)
chag[chag == 0] <- NA
chag[] <- scales::rescale(chag[], to = c(800, 1800))
chag <- raster::merge(chag, grid_1km)

e <- extent(6400000, 6900000, -120000, 870000)
mald <- crop(product1, e)
mald[mald == 0] <- NA
mald[] <- scales::rescale(mald[], to = c(800, 1400))
mald <- raster::merge(mald, grid_1km)

eco <- product1
eco[eco == 0] <- NA
eco[chag>0] <- NA
eco[mald>0] <- NA
eco[] <- scales::rescale(eco[], to = c(100, 1200))

eco[is.na(eco)] <- 0
eco[is.na(grid_1km)] <- NA
eco[chag>0] <- chag[chag>0]
eco[mald>0] <- mald[mald>0]

product1 <- eco

plot(eco)
```


*****************************************************************
*****************************************************************

# EXPORT

## Specify output directory and product file name
```{r}
(dest1_path_file1 <- paste0(dest1_path, "/", subtheme1, "_", name1, "_cutoff_", version, d_version, ".tif"))
```

## Export image of product raster(s)
```{r}
(img_path <- paste0(dest1_path, "/", subtheme1, "_", name1, "_cutoff_", version, d_version, ".png"))
prod1_scale <- product1
prod1_scale[prod1_scale == 0] <- NA
prod1_scale[] <- scales::rescale(prod1_scale[], to = c(1, 100))
prod1_scale[is.na(prod1_scale)] <- 0
prod1_scale[is.na(grid_1km)] <- NA


png(img_path, width = ncol(prod1_scale), height = nrow(prod1_scale))
pal <- colorRampPalette(rev(c('#d53e4f','#f46d43','#fdae61','#fee08b','#ffffbf','#e6f598','#abdda4','#66c2a5','#3288bd')))
plot(prod1_scale, maxpixels = ncell(prod1_scale), main = "", axes = FALSE, ylim=extent(prod1_scale)[3:4], 
     breaks = seq(0,100,1), col = pal(101), legend = F, box = F, colNA = "gray92")
dev.off()
```

## Export metadata
```{r}
sourcesym <- data.frame(matrix(data = NA, nrow = num_sources, ncol = 1))
colnames(sourcesym) <- "id"

for(i in 1:num_sources){
  sourcesym[i,1] <- source_list[i]
}

sourcesym
```

```{r}
sourcesym_path <- paste0(dest1_path_file1, "_sourcesym.txt")
write.table(sourcesym, sourcesym_path, row.names = F, sep = "\t")
```

## Export product
```{r}
writeRaster(product1, dest1_path_file1, COMPRESS=LZW, overwrite=TRUE)
```

